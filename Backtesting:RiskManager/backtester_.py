# -*- coding: utf-8 -*-
"""Backtester .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iialIhs8fvQawGLtsqQUYklIc0vbhkK8
"""

!pip install fredapi

import pandas as pd
import numpy as np
import yfinance as yf
import re
import fredapi
from google.colab import drive

drive.mount('/content/drive')

fred_api_key = "013796f71d8f9436e978cd20885652fb"
class DataHandler:
    def __init__(self, start= "2001-01-01", end=None):
        self.start = start
        self.end = end

        self.tickers = {
            "gold": "GC=F",
            "copper": "HG=F"
        }

    def clean(self, df, column):
        df.index = pd.to_datetime(df.index)
        df = df.ffill().bfill()
        mean = df[column].mean()
        std = df[column].std()
        z = (df[column] - mean)/std
        df.loc[z.abs() > 2, column] = np.nan
        df = df.ffill().bfill()
        return df



    def get_df(self, asset, column):
        if asset not in self.tickers:
            raise ValueError("not a valid asset")
        df = yf.download(self.tickers[asset], start=self.start, end=self.end)

        if isinstance(df.columns, pd.MultiIndex):
            df.columns = [' '.join(col).strip() for col in df.columns.values]
        # print(df) # Removed print statement to clean up dfput
        df = self.clean(df, column)
        return df[[column]]

    def get_gold_reserves_df(self):
      xlsx = '/content/drive/MyDrive/Fall 2025 ML Commodities Shared Folder/Data/Quarterly_gold_and_FX_Reserves_Q2_2025 (2).xlsx'
      df = pd.read_excel(xlsx,sheet_name="Gold (US$ millions)", header=1)
      world_row = df[df.iloc[:, 0].astype(str).str.strip().eq("World")]
      quarter_cols = [c for c in df.columns if isinstance(c, str) and re.match(r"^Q[1-4]\s*\d{4}$", c.strip())]
      quarterly_series = world_row[quarter_cols].iloc[0]
      idx = []
      for label in quarterly_series.index.astype(str):
          q = re.match(r"^Q([1-4])\s*(\d{4})$", label.strip())
          idx.append(f"{q.group(2)}Q{q.group(1)}")
      quarterly_series.index = pd.PeriodIndex(idx, freq="Q-DEC").to_timestamp(how="end")
      quarterly_series = pd.to_numeric(quarterly_series, errors="coerce")
      monthly_series = quarterly_series.resample("M").ffill()
      result = pd.DataFrame({"Monthly Gold World's Reserves(USD millions)": monthly_series})
      result.index.name = "date"
      if self.end is not None:
        result = result[(result.index >= self.start) & (result.index <= self.end)]
      else:
         result = result[(result.index >= self.start)]
      result["3-Month Lagged Monthly Gold World's Reserves(USD millions)"] = result["Monthly Gold World's Reserves(USD millions)"].shift(3)
      return result


    def get_macroeconomic_data(self,fred_series_id =  ["DGS10", "DFII10", "DTWEXBGS"]):
        fred = fredapi.Fred(api_key=fred_api_key)
        data = {}
        for series in fred_series_id:
            # Corrected variable name to self.start and self.end
            data[series] = fred.get_series(series, observation_start= self.start, observation_end = self.end)
        return pd.DataFrame(data)

    def merge_all_data(self):
        # Corrected column names based on yfinance output
        gold_df = self.get_df("gold", "Close GC=F")
        macro_df = self.get_macroeconomic_data()
        copper_df = self.get_df("copper", "Close HG=F")
        gold_reserves_df = self.get_gold_reserves_df()
        merged_df = gold_df.merge(macro_df, left_index=True, right_index=True, how='outer')
        merged_df = merged_df.merge(copper_df, left_index=True, right_index=True, how='outer')
        merged_df = merged_df.merge(gold_reserves_df, left_index=True, right_index=True, how='outer')
        merged_df = merged_df.ffill().bfill()
        return merged_df

    def add_leak_cols(self, df, price_col):
      if price_col not in df.columns:
        raise ValueError(f"price_col '{price_col}' not found in df columns")
      p = df[price_col]
      df["Rolling_Mean"] = p.rolling(window = 20).mean()
      df["Rolling_Std"] = p.rolling(window = 20).std()
      df["Returns"] = p.pct_change()
      df["Log_Returns"] = np.log(p).diff()
      # Volatility: rolling std of past returns (20-day window)
      df["Volatility"] = df["Returns"].rolling(20, min_periods=20).std()
      # Trend: SMA(10) - SMA(30), both past-only
       # More sophisticated trend detection
      def detect_trend(returns, volatility):
          if returns > 2 * volatility:
              return 2  # Strong Bullish
          elif returns < -2 * volatility:
              return 0  # Strong Bearish
          else:
              return 1  # Neutral
      df['Trend'] = df.apply(lambda row: detect_trend(row['Log_Returns'], row['Volatility']), axis=1)
      df['Trend'] = df['Trend'].shift(-1)
      df.dropna(subset=['Trend'], inplace=True)

      return df

#testing the functioning of the datahandler class
dh = DataHandler('2001-01-01', '2025-01-01')
dh.add_leak_cols(dh.merge_all_data(), "Close GC=F").to_csv('/content/metal_data.csv')

"""XGBoost"""

!pip install pandas requests fredapi pandas_ta -q
!pip install optuna
!pip install ipywidgets
!pip install yfinance
!pip install imblearn

import pandas as pd
import numpy as np
import xgboost as xgb
#import pandas_ta as ta
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, f1_score, roc_auc_score
from scipy.fftpack import fft
import requests
from fredapi import Fred
import optuna
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import display
from IPython import get_ipython
from imblearn.over_sampling import SMOTE
import yfinance as yf
from sklearn.decomposition import PCA
from scipy import signal
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder

!pip install --upgrade numpy scipy xgboost

def optimize_xgboost(X_train, y_train):
    """Grid search for optimal XGBoost parameters."""

    # Convert 'Ticker' and 'Cycle_Phase' to numerical before optimization
    for col in ['Ticker', 'Cycle_Phase']:
        if col in X_train.columns:
            X_train[col] = X_train[col].astype('category').cat.codes

    def objective(trial):
        params = {
            'max_depth': trial.suggest_int('max_depth', 2, 4),
            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),
            'n_estimators': trial.suggest_int('n_estimators', 100, 250),
            'subsample': trial.suggest_float('subsample', 0.6, 0.8),
            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),
            'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.1, 1.0),
            'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.1, 1.0),
            'min_child_weight': trial.suggest_int('min_child_weight', 3, 5)
        }
        class_weights = {0: 1, 1: 1, 2: len(y_train) / (2 * np.sum(y_train == 2))}

        from sklearn.model_selection import TimeSeriesSplit
        tscv = TimeSeriesSplit(n_splits=3)
        val_scores = []
        for tr_idx, va_idx in tscv.split(X_train):
            X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]
            y_tr, y_va = y_train[tr_idx], y_train[va_idx]
            model = xgb.XGBClassifier(
                **params,
                scale_pos_weight=class_weights,
                tree_method='hist',
                enable_categorical=True,
                eval_metric='mlogloss'
            )
            model.fit(X_tr, y_tr)
            val_scores.append(accuracy_score(y_va, model.predict(X_va)))
        return float(np.mean(val_scores))

    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=20)
    return study.best_params

def train_models(df):
    # Drop any remaining non-numeric or non-categorical columns
    numeric_cols = df.select_dtypes(include=['int64', 'float64', 'category']).columns
    df = df[numeric_cols]

    leak_cols = ['Trend', 'Returns', 'Log_Returns', 'Volatility']
    features = [col for col in df.columns if col not in leak_cols]
    X = df[features]
    y = LabelEncoder().fit_transform(df['Trend']) # the main problem right now

    # Prevents overlap bleed between the end of train and start of test
    split_idx = int(len(df) * 0.8)
    embargo = 5  # trading days; adjust as needed
    train_df = df.iloc[:split_idx - embargo]
    test_df  = df.iloc[split_idx + embargo:]

    le = LabelEncoder()
    y_train = le.fit_transform(train_df['Trend'])
    y_test  = le.transform(test_df['Trend'])
    X_train = train_df.drop(columns=['Trend'])
    X_test  = test_df.drop(columns=['Trend'])
    print(set(y_test) - set(y_train))

    # Convert categorical columns to numerical codes if any remain
    for col in X_train.select_dtypes(include=['category', 'object']).columns:
        X_train[col] = X_train[col].astype('category').cat.codes
        X_test[col] = X_test[col].astype('category').cat.codes

    print(pd.Series(y_train).value_counts())
    print(pd.Series(y_test).value_counts())

    best_params = optimize_xgboost(X_train, y_train)

    model = xgb.XGBClassifier(
        **best_params,
        tree_method='hist',
        enable_categorical=True,
        eval_metric='mlogloss'
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    y_pred_proba = model.predict_proba(X_test)
    auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')
    print("AUC Score:", auc_score)

    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    print("Confusion Matrix:")
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

    print("Accuracy Score:", accuracy_score(y_test, y_pred))
    print("F1 Score:", f1_score(y_test, y_pred, average='weighted'))

    # Train Accuracy
    y_train_pred = model.predict(X_train)
    train_accuracy = accuracy_score(y_train, y_train_pred)
    print(f"Training Accuracy: {train_accuracy:.4f}")

    # Test Accuracy
    y_test_pred = model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_test_pred)
    print(f"Test Accuracy: {test_accuracy:.4f}")

    return model, X_train, X_test, y_train, y_test, X, y

dh = DataHandler('2015-01-01', '2024-01-01')
total_metal_data = dh.merge_all_data()
total_metal_data = dh.add_leak_cols(total_metal_data.dropna(), "Close GC=F")
XGBmodel, X_train, X_test, y_train, y_test, X, y = train_models(total_metal_data)###Need to replace inside parenthesis with gold data, need elias help ELIAS UPDATE:
XGBmodel.save_model("model_sklearn.json")
save_path = "/content/drive/MyDrive/QuantModels/model_sklearn.json"

"""Arima Garch"""

!pip install arch
!pip install pmdarima

import os
import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import logging
from scipy.signal import detrend, find_peaks, stft, periodogram
from scipy.fftpack import fft, fftfreq
from statsmodels.tsa.filters.hp_filter import hpfilter
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima_model import ARIMA

from arch import arch_model
from statsmodels.tsa.statespace.sarimax import SARIMAX

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def fit_sarima_garch(train_data, seasonal_period, garch_order=(1, 1), d_order=0):
    """
    Fits a SARIMA model using auto_arima (with a predetermined differencing order)
    and then fits a GARCH model on the residuals.
    """
    # Fit SARIMA (note: d is forced to d_order based on our stationarity tests)
    model = pm.auto_arima(
        train_data,
        seasonal=True,
        m=seasonal_period,
        d=d_order,
        stepwise=True,
        suppress_warnings=True,
        trace=True,
        start_p=1, start_q=1, max_p=3, max_q=3,
        start_P=0, start_Q=0, max_P=2, max_Q=2,
        n_jobs=-1,
        parallel=True,
        error_action='ignore'
    )
    print(f"Fitted SARIMA order: {model.order}, seasonal order: {model.seasonal_order}")

    # Use residuals from the SARIMA model (limit to a rolling window if needed)
    residuals = model.resid()
    window_length = 300  # adjust as necessary
    if len(residuals) > window_length:
        residuals = residuals[-window_length:]

    # Fit GARCH on the SARIMA residuals
    garch = arch_model(residuals, vol='Garch', p=garch_order[0], q=garch_order[1])
    garch_fit = garch.fit(update_freq=5, disp='off')

    return model, garch_fit

def forecast_sarima_garch(model, garch_model, steps):
    """
    Forecasts future values using the fitted SARIMA and GARCH models.
    """
    # Forecast with the SARIMA model
    sarima_forecast = model.predict(n_periods=steps)

    # Forecast volatility using the GARCH model
    garch_forecast = garch_model.forecast(horizon=steps)
    volatility = np.sqrt(garch_forecast.variance.iloc[-1])

    return sarima_forecast, volatility
arima_model, garch_fit = fit_sarima_garch(train_data, seasonal_period=12)### need to change train data again

"""VECM"""

def fit_vecm_model(data, coint_rank, lag_order, exog=None, deterministic = "ci"):
    """
    Fits a VECM model with optional exogenous variables.

    Parameters:
    - data: DataFrame or array-like
        Endogenous variables (e.g., SLV and GLD prices).
    - coint_rank: int
        Cointegration rank (from Johansen test).
    - lag_order: int
        Number of lags for the VAR part (e.g., 1 or 2).
    - exog: DataFrame or array-like (optional)
        Exogenous variables (e.g., differenced CPI).

    Returns:
    - Fitted VECM model results.
    """
    model = VECM(
        endog=data,
        exog=exog,  # Pass exogenous variables here
        k_ar_diff=1,
        coint_rank=1,
        deterministic=deterministic # "ci" = constant in coint. eq., "li" = linear trend
    )
    vecm_res = model.fit()
    return vecm_res
  VECMmodel = fit_vecm_model(train_data, coint_rank=1, lag_order=1) ### Need to change train data

"""## Strategy Helpers"""

@dataclass
class TSParams:
    threshold: float = 0.0           # enter long if forecast price > current price*(1+threshold)
    stop_loss: float = 0.05          # 5% stop
    take_profit: float = 0.10        # 10% take profit
    max_holding_days: Optional[int] = None

    # position sizing
    sizing_method: str = "confidence"  # 'fixed' | 'percentage' | 'confidence' | 'kelly'
    fixed_size: float = 1.0
    pct_of_notional: float = 0.25
    conf_scale: float = 0.05           # bigger -> smaller sizes for a given forecast edge
    kelly_p: float = 0.55
    kelly_b: float = 1.0
    max_total_size: Optional[float] = 3.0

    # trading cost
    fee_bps: float = 1.0

def _trade_cost(bps: float) -> float:
    return (bps or 0.0) / 10000.0

def _size_from_method(method: str, px: float, pred: float, p: TSParams) -> float:
    if method == "fixed":
        return float(p.fixed_size)
    if method == "percentage":
        return float(np.clip(p.pct_of_notional, 0.0, 1.0))
    if method == "confidence":
        rel = abs(pred - px) / max(px, 1e-12)
        return float(min(1.0, rel / max(p.conf_scale, 1e-6)))
    if method == "kelly":
        pr = np.clip(p.kelly_p, 1e-6, 1-1e-6); b = max(p.kelly_b, 1e-6)
        return float(np.clip(pr - (1-pr)/b, 0.0, 1.0))
    return 1.0

def apply_trading_script_rules(prices: pd.Series, forecast_prices: pd.Series, params: TSParams) -> pd.DataFrame:
    """Vector-safe trading loop. Returns columns: price, ret, f_price, pos, unit, strategy_ret, equity."""
    prices = pd.to_numeric(prices, errors="coerce").dropna()
    forecast_prices = pd.to_numeric(forecast_prices, errors="coerce")
    idx = prices.index.intersection(forecast_prices.index)
    px = prices.reindex(idx)
    fp = forecast_prices.reindex(idx)

    df = pd.DataFrame({
        "price": px.astype(float),
        "ret": px.astype(float).pct_change().fillna(0.0),
        "f_price": fp
    })
    # create outputs up front (these must exist)
    df["pos"] = 0.0
    df["unit"] = 0.0
    df["strategy_ret"] = 0.0

    in_trade = False
    entry_px = None
    entry_side = 0.0  # +1 for long
    size_mult = 0.0
    total_size = 0.0
    open_cost = _trade_cost(params.fee_bps)
    close_cost = _trade_cost(params.fee_bps)

    for i in range(1, len(df)):
        px_i = float(df.iat[i, df.columns.get_loc("price")])
        pred = df.iat[i, df.columns.get_loc("f_price")]

        if np.isnan(pred) or px_i <= 0.0:
            # carry state/ret if in pos
            if in_trade:
                df.iat[i, df.columns.get_loc("pos")] = entry_side * size_mult
                df.iat[i, df.columns.get_loc("unit")] = total_size
                df.iat[i, df.columns.get_loc("strategy_ret")] = df.iat[i, df.columns.get_loc("pos")] * df.iat[i, df.columns.get_loc("ret")]
            continue

        want_long = (pred > px_i * (1.0 + params.threshold))

        if not in_trade:
            if want_long:
                entry_px = px_i; entry_side = 1.0
                size_mult = _size_from_method(params.sizing_method, px_i, pred, params)
                total_size = size_mult if params.max_total_size is None else min(size_mult, params.max_total_size)
                size_mult = total_size
                in_trade = True
                df.iat[i, df.columns.get_loc("pos")] = entry_side * size_mult
                df.iat[i, df.columns.get_loc("unit")] = total_size
                df.iat[i, df.columns.get_loc("strategy_ret")] = df.iat[i, df.columns.get_loc("pos")] * df.iat[i, df.columns.get_loc("ret")] - open_cost*abs(entry_side)
            continue

        # in trade
        move = px_i / entry_px - 1.0
        exit_now = False
        if params.stop_loss is not None and move <= -params.stop_loss: exit_now = True
        if params.take_profit is not None and move >=  params.take_profit and not exit_now: exit_now = True

        if exit_now or (not want_long):
            df.iat[i, df.columns.get_loc("pos")] = 0.0
            df.iat[i, df.columns.get_loc("unit")] = 0.0
            df.iat[i, df.columns.get_loc("strategy_ret")] = size_mult * df.iat[i, df.columns.get_loc("ret")] - close_cost*abs(entry_side)
            in_trade = False; entry_px = None; entry_side = 0.0; size_mult = 0.0; total_size = 0.0
        else:
            # still long; optional scale-up if pred > px
            if pred > px_i:
                add_mult = _size_from_method(params.sizing_method, px_i, pred, params)
                new_total = total_size + add_mult
                if params.max_total_size is not None:
                    new_total = float(min(new_total, params.max_total_size))
                total_size = new_total; size_mult = new_total
            df.iat[i, df.columns.get_loc("pos")] = entry_side * size_mult
            df.iat[i, df.columns.get_loc("unit")] = total_size
            df.iat[i, df.columns.get_loc("strategy_ret")] = df.iat[i, df.columns.get_loc("pos")] * df.iat[i, df.columns.get_loc("ret")]

    df["equity"] = (1.0 + df["strategy_ret"]).cumprod()
    return df

def run_trading_script_with_backtester(bt_obj, assets: Dict[str, pd.Series], models: Dict[str, Any], ts_params: TSParams):
    """
    Your Backtester.walk_forward(series, model_instance) returns a DataFrame ['y_pred','y_true'] on test dates.
    We align so decision at t-1 uses forecast for t (live-trading causality).
    """
    def _metrics(equity: pd.Series, rets: pd.Series) -> Dict[str, float]:
        equity = pd.to_numeric(equity, errors="coerce").dropna()
        rets   = pd.to_numeric(rets,   errors="coerce").dropna()
        if equity.empty:
            return {"CAGR": 0.0, "Sharpe": 0.0, "MaxDD": 0.0, "Sortino": 0.0}
        T_days = (equity.index[-1] - equity.index[0]).days or max(len(equity), 1)
        years  = T_days / 365.25
        cagr   = equity.iloc[-1] ** (1/years) - 1 if years > 0 else 0.0
        mu     = rets.mean() * 252
        sig    = rets.std(ddof=0) * (252 ** 0.5)
        sharpe = mu / sig if sig > 1e-12 else 0.0
        maxdd  = (equity / equity.cummax() - 1.0).min()
        d_sig  = rets[rets < 0].std(ddof=0) * (252 ** 0.5)
        sortino = mu / d_sig if d_sig > 1e-12 else 0.0
        return {"CAGR": float(cagr), "Sharpe": float(sharpe), "MaxDD": float(maxdd), "Sortino": float(sortino)}

    out: Dict[str, Dict[str, Any]] = {}
    for asset_name, series in assets.items():
        out[asset_name] = {}
        for model_name, model_instance in models.items():
            fc_df = bt_obj.walk_forward(series, model_instance)   # -> DataFrame with ['y_pred','y_true']
            y_pred = pd.to_numeric(fc_df["y_pred"], errors="coerce") if "y_pred" in fc_df.columns else pd.to_numeric(fc_df.squeeze(), errors="coerce")

            # Align: forecast for t is used to decide at t-1
            f_for_signal  = y_pred.shift(-1)
            px_for_signal = series.reindex(f_for_signal.index).astype(float)
            mask = (~f_for_signal.isna()) & (~px_for_signal.isna())

            df = apply_trading_script_rules(px_for_signal[mask], f_for_signal[mask], ts_params)
            out[asset_name][model_name] = {
                "df": df,
                "metrics": _metrics(df["equity"], df["strategy_ret"]),
                "diag": {
                    "n_forecasts": int(y_pred.notna().sum()),
                    "n_signal_rows": int(mask.sum()),
                    "position_rate": float((df["pos"] != 0).mean()),
                },
            }
    return out

from statsmodels.tsa.ar_model import AutoReg
from statsmodels.tsa.arima.model import ARIMA

class RandomWalk:
    #Random walk using Arima
    def __init__(self):
        self.model = None
        self.results = None

    def fit(self, series):
        # ARIMA(0,1,0) = Random Walk
        self.model = ARIMA(series, order=(0, 1, 0))
        self.results = self.model.fit()

    def predict(self, steps=1):
        if self.results is None:
            raise ValueError("Model not fitted yet.")
        return self.results.forecast(steps=steps)


class AR1:
    #AR1 model
    def __init__(self):
        self.model = None
        self.results = None

    def fit(self, series):
        returns = series.pct_change().dropna()
        self.model = AutoReg(returns, lags=1, old_names=False)
        self.results = self.model.fit()
        self.last_price = series.iloc[-1]

    def predict(self, steps=1):
        if self.results is None:
            raise ValueError("Model not fitted yet.")

        # Forecast returns
        returns_series = self.results.predict(start=len(self.results.model.endog),
                                              end=len(self.results.model.endog) + steps - 1)
        last_price = self.last_price
        preds = []
        for r in returns_series:
            next_price = last_price * (1 + r)
            preds.append(next_price)
            last_price = next_price
        return preds

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.vector_ar.vecm import select_coint_rank, coint_johansen
from sklearn.metrics import mean_squared_error, mean_absolute_error
from statsmodels.tsa.filters.hp_filter import hpfilter
import warnings
warnings.filterwarnings('ignore')

# %matplotlib inline
plt.style.use('ggplot')

class VECM:
  #VECM model
  def __init__(self):
    self.model = None
    self.results = None



import numpy as np
import pandas as pd

class Backtester:
    #Walk forward backtester
    def __init__(self, train_size=0.8, window=252):
        self.train_size = train_size  # Fraction of window used for training
        self.window = window          # Total window size (train + test)
        self.macro_features = None

    def add_macro_features(self, macro_df):
        self.macro_features = macro_df

    def walk_forward(self, series, model_instance):
        n = len(series)
        train_len = int(self.train_size * self.window)
        test_len = self.window - train_len
        preds = []
        actuals = []
        indices = []

        for start in range(0, n - self.window + 1, test_len):
            train = series.iloc[start : start + train_len]
            test = series.iloc[start + train_len : start + self.window]
            if len(test) == 0:
                break
            # Use the provided model instance directly
            model_instance.fit(train)
            y_pred = model_instance.predict(steps=len(test))


            # Handle output type (list or Series)
            #Got this part from chat because I couldnt figure out data type error
            if hasattr(y_pred, 'values'):
                y_pred = y_pred.values
            preds.extend(y_pred)
            actuals.extend(test.values)
            indices.extend(test.index)
        return pd.DataFrame({'y_pred': preds, 'y_true': actuals}, index=indices)


    def run_all(self, series1, series2):
        results = {}
        for name, series in zip(['gold', 'copper'], [series1, series2]):
            rw_results = self.walk_forward(series, RandomWalk())
            ar1_results = self.walk_forward(series, AR1())
            results[name] = {
                'RW': {'preds': rw_results['y_pred'], 'actuals': rw_results['y_true'], 'metrics': self.compute_metrics(rw_results)},
                'AR1': {'preds': ar1_results['y_pred'], 'actuals': ar1_results['y_true'], 'metrics': self.compute_metrics(ar1_results)}
            }
        return results

    def compute_metrics(self, df):
        mse = np.mean((df['y_pred'] - df['y_true']) ** 2)
        mae = np.mean(np.abs(df['y_pred'] - df['y_true']))
        return {'MSE': mse, 'MAE': mae}
class AutoArimaModel:
    def __init__(self, **kwargs):
        self.kwargs = kwargs
        self.model = None

    def fit(self, series):
        from pmdarima import auto_arima
        self.model = auto_arima(series, **self.kwargs)

    def predict(self, steps=1):
        return self.model.predict(n_periods=steps)


class SarimaxModel:
    def __init__(self, order=(1,1,1), seasonal_order=(1,1,1,7)):
        self.order = order
        self.seasonal_order = seasonal_order
        self.model = None

    def fit(self, series):
        from statsmodels.tsa.statespace.sarimax import SARIMAX
        self.model = SARIMAX(series, order=self.order,
                             seasonal_order=self.seasonal_order,
                             enforce_stationarity=False,
                             enforce_invertibility=False).fit(disp=False)

    def predict(self, steps=1):
        return self.model.forecast(steps=steps)

from statsmodels.tsa.vector_ar.vecm import VECM

class VECM:
  def init(self,data, ):
    self.model = None
    self.results = None


  def fit_vecm(self,data, coint_rank, lag_order, exog=None, deterministic = "ci"):
    model = VECM(
        endog=data,
        exog=exog,  # Pass exogenous variables here
        k_ar_diff=1,
        coint_rank=1,
        deterministic=deterministic # "ci" = constant in coint. eq., "li" = linear trend
    )
    vecm_res = model.fit()
    return vecm_res



"""Dont know why this is giving a ton of warnings before output"""

import numpy as np ## DELTE THIS CELL - make sure the duplicate copy running the backtester with sortino, sharpe, max dd works
import pandas as pd  # you need this import
import yfinance as yf
from statsmodels.tsa.ar_model import AutoReg
from statsmodels.tsa.arima.model import ARIMA
from typing import Dict, Any
import re
import fredapi


fred_api_key = "013796f71d8f9436e978cd20885652fb"
class DataHandler:
    def __init__(self, start= "2001-01-01", end=None):
        self.start = start
        self.end = end

        self.tickers = {
            "gold": "GC=F",
            "copper": "HG=F"
        }

    def clean(self, df, column):
        df.index = pd.to_datetime(df.index)
        df = df.ffill().bfill()
        mean = df[column].mean()
        std = df[column].std()
        z = (df[column] - mean)/std
        df.loc[z.abs() > 2, column] = np.nan
        df = df.ffill().bfill()
        return df



    def get_df(self, asset, column):
        if asset not in self.tickers:
            raise ValueError("not a valid asset")
        df = yf.download(self.tickers[asset], start=self.start, end=self.end)

        if isinstance(df.columns, pd.MultiIndex):
            df.columns = [' '.join(col).strip() for col in df.columns.values]
        print(df)
        df = self.clean(df, column)
        return df[[column]]
    def get_gold_reserves_df(self):
      xlsx = '/content/Quarterly_gold_and_FX_Reserves_Q2_2025 (2).xlsx'
      df = pd.read_excel(xlsx,sheet_name="Gold (US$ millions)", header=1)
      world_row = df[df.iloc[:, 0].astype(str).str.strip().eq("World")]
      quarter_cols = [c for c in df.columns if isinstance(c, str) and re.match(r"^Q[1-4]\s*\d{4}$", c.strip())]
      quarterly_series = world_row[quarter_cols].iloc[0]
      idx = []
      for label in quarterly_series.index.astype(str):
          q = re.match(r"^Q([1-4])\s*(\d{4})$", label.strip())
          idx.append(f"{q.group(2)}Q{q.group(1)}")
      quarterly_series.index = pd.PeriodIndex(idx, freq="Q-DEC").to_timestamp(how="end")
      quarterly_series = pd.to_numeric(quarterly_series, errors="coerce")
      monthly_series = quarterly_series.resample("M").ffill()
      result = pd.DataFrame({"Monthly Gold World's Reserves(USD millions)": monthly_series})
      result.index.name = "date"
      result = result[(result.index >= self.start) & (result.index <= self.end)]
      result["3-Month Lagged Monthly Gold World's Reserves(USD millions)"] = result["Monthly Gold World's Reserves(USD millions)"].shift(3)
      return result


     def get_macroeconomic_data(self,fred_series_id =  ["DGS10", "DFII10", "DTWEXBGS"]):
        fred = fredapi.Fred(api_key=fred_api_key)
        data = {}
        for series in fred_series_id:
            # Corrected variable name to self.start and self.end
            data[series] = fred.get_series(series, observation_start= self.start, observation_end = self.end)
        return pd.DataFrame(data)

    def merge_all_data(self):
        # Corrected column names based on yfinance output
        gold_df = self.get_df("gold", "Close GC=F")
        macro_df = self.get_macroeconomic_data()
        copper_df = self.get_df("copper", "Close HG=F")
        gold_reserves_df = self.get_gold_reserves_df()
        merged_df = gold_df.merge(macro_df, left_index=True, right_index=True, how='outer')
        merged_df = merged_df.merge(copper_df, left_index=True, right_index=True, how='outer')
        merged_df = merged_df.merge(gold_reserves_df, left_index=True, right_index=True, how='outer')
        merged_df = merged_df.ffill().bfill()
        return merged_df


class RandomWalk:
    #Random walk using Arima
    def __init__(self):
        self.model = None
        self.results = None

    def fit(self, series):
        # ARIMA(0,1,0) = Random Walk
        self.model = ARIMA(series, order=(0, 1, 0))
        self.results = self.model.fit()

    def predict(self, steps=1):
        if self.results is None:
            raise ValueError("Model not fitted yet.")
        return self.results.forecast(steps=steps)


class AR1:
    #AR1 model
    def __init__(self):
        self.model = None
        self.results = None

    def fit(self, series):
        returns = series.pct_change().dropna()
        self.model = AutoReg(returns, lags=1, old_names=False)
        self.results = self.model.fit()
        self.last_price = series.iloc[-1]

    def predict(self, steps=1):
        if self.results is None:
            raise ValueError("Model not fitted yet.")

        # Forecast returns
        returns_series = self.results.predict(start=len(self.results.model.endog),
                                              end=len(self.results.model.endog) + steps - 1)
        last_price = self.last_price
        preds = []
        for r in returns_series:
            next_price = last_price * (1 + r)
            preds.append(next_price)
            last_price = next_price
        return preds

class Backtester:
    #Walk forward backtester
    def __init__(self, train_size=0.8, window=252):
        self.train_size = train_size  # Fraction of window used for training
        self.window = window          # Total window size (train + test)
        self.macro_features = None

    def add_macro_features(self, macro_df):
        self.macro_features = macro_df

    def walk_forward(self, series, model_instance):
        n = len(series)
        train_len = int(self.train_size * self.window)
        test_len = self.window - train_len
        preds = []
        actuals = []
        indices = []

        for start in range(0, n - self.window + 1, test_len):
            train = series.iloc[start : start + train_len]
            test = series.iloc[start + train_len : start + self.window]
            if len(test) == 0:
                break
            # Use the provided model instance directly
            model_instance.fit(train)
            y_pred = model_instance.predict(steps=len(test))


            # Handle output type (list or Series)
            #Got this part from chat because I couldnt figure out data type error
            if hasattr(y_pred, 'values'):
                y_pred = y_pred.values
            preds.extend(y_pred)
            actuals.extend(test.values)
            indices.extend(test.index)
        return pd.DataFrame({'y_pred': preds, 'y_true': actuals}, index=indices)


    def run_all(self, series1, series2):
        results = {}
        for name, series in zip(['gold', 'copper'], [series1, series2]):
            rw_results = self.walk_forward(series, RandomWalk())
            ar1_results = self.walk_forward(series, AR1())
            results[name] = {
                'RW': {'preds': rw_results['y_pred'], 'actuals': rw_results['y_true'], 'metrics': self.compute_metrics(rw_results)},
                'AR1': {'preds': ar1_results['y_pred'], 'actuals': ar1_results['y_true'], 'metrics': self.compute_metrics(ar1_results)}
            }
        return results

    def compute_metrics(self, df):
        mse = np.mean((df['y_pred'] - df['y_true']) ** 2)
        mae = np.mean(np.abs(df['y_pred'] - df['y_true']))
        return {'MSE': mse, 'MAE': mae}
class AutoArimaModel:
    def __init__(self, **kwargs):
        self.kwargs = kwargs
        self.model = None

    def fit(self, series):
        from pmdarima import auto_arima
        self.model = auto_arima(series, **self.kwargs)

    def predict(self, steps=1):
        return self.model.predict(n_periods=steps)


class SarimaxModel:
    def __init__(self, order=(1,1,1), seasonal_order=(1,1,1,7)):
        self.order = order
        self.seasonal_order = seasonal_order
        self.model = None

    def fit(self, series):
        from statsmodels.tsa.statespace.sarimax import SARIMAX
        self.model = SARIMAX(series, order=self.order,
                             seasonal_order=self.seasonal_order,
                             enforce_stationarity=False,
                             enforce_invertibility=False).fit(disp=False)

    def predict(self, steps=1):
        return self.model.forecast(steps=steps)


# Placeholder for TSParams and apply_trading_script_rules - Replace with your actual implementation
class TSParams:
    def __init__(self, **kwargs):
        for key, value in kwargs.items():
            setattr(self, key, value)

def apply_trading_script_rules(series, forecasts, ts_params):
    # This is a placeholder function - Replace with your actual trading script logic
    # It should take the original series, model forecasts, and trading parameters
    # and return a DataFrame with trading results including 'equity' and 'strategy_ret'
    print("Applying placeholder trading rules...")
    df = pd.DataFrame({'y_pred': forecasts['y_pred'], 'y_true': forecasts['y_true']}, index=forecasts.index)
    df['equity'] = 1.0 # Placeholder equity
    df['strategy_ret'] = 0.0 # Placeholder strategy returns
    return df

def run_trading_script_with_backtester(
    bt_obj,
    assets: Dict[str, pd.Series],
    models: Dict[str, Any],
    ts_params
) -> Dict[str, Dict[str, Any]]:
    """
    Compatibility runner: tries (series, model, fit_interval=..., min_points=...) and
    falls back to (series, model) if your Backtester doesn't accept those kwargs.
    """
    def _metrics(equity: pd.Series, rets: pd.Series) -> Dict[str, float]:
        equity = equity.dropna(); rets = rets.dropna()
        if equity.empty:
            return {"CAGR": 0.0, "Sharpe": 0.0, "MaxDD": 0.0, "Sortino": 0.0}
        T_days = (equity.index[-1] - equity.index[0]).days or max(len(equity), 1)
        years = T_days / 365.25
        cagr = equity.iloc[-1] ** (1/years) - 1 if years > 0 else 0.0
        mu = rets.mean() * 252
        sig = rets.std(ddof=0) * (252 ** 0.5)
        sharpe = mu / sig if sig > 1e-12 else 0.0
        maxdd = (equity / equity.cummax() - 1.0).min()
        d_sig = rets[rets < 0].std(ddof=0) * (252 ** 0.5)
        sortino = mu / d_sig if d_sig > 1e-12 else 0.0
        return {"CAGR": float(cagr), "Sharpe": float(sharpe), "MaxDD": float(maxdd), "Sortino": float(sortino)}

    out: Dict[str, Dict[str, Any]] = {}
    for asset_name, series in assets.items():
        out[asset_name] = {}
        for model_name, model_obj in models.items():
            # Try extended signature; fall back to basic
            try:
                fc = bt_obj.walk_forward(
                    series, model_obj,
                    fit_interval=getattr(ts_params, "fit_interval", 5),
                    min_points=getattr(ts_params, "min_points", 30)
                )
            except TypeError:
                fc = bt_obj.walk_forward(series, model_obj)

            df = apply_trading_script_rules(series, fc, ts_params)
            out[asset_name][model_name] = {
                "df": df,
                "metrics": _metrics(df["equity"], df["strategy_ret"])
            }
    return out
    def _metrics(equity: pd.Series, rets: pd.Series) -> Dict[str, float]:
        equity = equity.dropna(); rets = rets.dropna()
        if equity.empty:
            return {"CAGR": 0.0, "Sharpe": 0.0, "MaxDD": 0.0, "Sortino": 0.0}
        T_days = (equity.index[-1] - equity.index[0]).days or max(len(equity), 1)
        years = T_days / 365.25
        cagr = equity.iloc[-1] ** (1/years) - 1 if years > 0 else 0.0
        mu = rets.mean() * 252
        sig = rets.std(ddof=0) * (252 ** 0.5)
        sharpe = mu / sig if sig > 1e-12 else 0.0
        maxdd = (equity / equity.cummax() - 1.0).min()
        d_sig = rets[rets < 0].std(ddof=0) * (252 ** 0.5)
        sortino = mu / d_sig if d_sig > 1e-12 else 0.0
        return {"CAGR": float(cagr), "Sharpe": float(sharpe), "MaxDD": float(maxdd), "Sortino": float(sortino)}

    out: Dict[str, Dict[str, Any]] = {}
    for asset_name, series in assets.items():
        out[asset_name] = {}
        for model_name, model_obj in models.items():
            # Try extended signature; fall back to basic
            try:
                fc = bt_obj.walk_forward(
                    series, model_obj,
                    fit_interval=getattr(ts_params, "fit_interval", 5),
                    min_points=getattr(ts_params, "min_points", 30)
                )
            except TypeError:
                fc = bt_obj.walk_forward(series, model_obj)

            df = apply_trading_script_rules(series, fc, ts_params)
            out[asset_name][model_name] = {
                "df": df,
                "metrics": _metrics(df["equity"], df["strategy_ret"])
            }
    return out


def main():
    # 1) Load data
    dh = DataHandler(start="2015-01-01", end="2024-01-01")
    gold_df   = dh.get_df("gold",   "Close GC=F")
    copper_df = dh.get_df("copper", "Close HG=F")

    gold_series   = gold_df["Close GC=F"].asfreq("B").ffill()     # business days + fill
    copper_series = copper_df["Close HG=F"].asfreq("B").ffill()

    # 2) Initialize backtester
    bt = Backtester(train_size=0.8, window=252)

    # 3) Optional macro features (placeholders ok)
    macro_df = gold_df.copy()
    macro_df["copper_SO2"] = np.nan
    macro_df["NTL"]        = np.nan
    macro_df["oil"]        = np.nan
    macro_df["gold_macro"] = np.nan
    bt.add_macro_features(macro_df)

    # 4) Keep your original run_all + printed metrics
    results = bt.run_all(gold_series, copper_series)
    for asset in ["gold", "copper"]:
        print(f"\n=== {asset.upper()} RESULTS ===")
        for model in ["RW", "AR1"]:
            metrics = results[asset][model]["metrics"]
            # print(f"{k}: {v:.6f}" if isinstance(v, float) else f"{k}: {v}")

    # 5) ORIGINAL errors (MSE/MAE) via walk_forward for RW & AR1
    models = {"RW": RandomWalk(), "AR1": AR1()}   # pass INSTANCES
    def _errors_for(series, model_instance):
        fc = bt.walk_forward(series, model_instance)   # forecasted next price series
        actual = series.shift(-1)                   # align to next-day actual
        both = pd.concat({"fc": fc, "y": actual}, axis=1).dropna()
        mse = ((both["fc"] - both["y"])**2).mean()
        mae = (both["fc"] - both["y"]).abs().mean()
        return mse, mae

    err_rows = []
    for asset_name, s in {"gold": gold_series, "copper": copper_series}.items():
        for mname, model_instance in models.items():
            mse, mae = _errors_for(s, model_instance)
            err_rows.append({"asset": asset_name, "model": mname, "MSE": mse, "MAE": mae})
    mse_mae_table = pd.DataFrame(err_rows).sort_values(["asset","model"])
    print("\n=== Original Forecast Errors (no trading) ===")
    display(mse_mae_table)

    # 6) Trading strategy (threshold + SL/TP) on the same forecasts
    # Make sure TSParams + run_trading_script_with_backtester are defined earlier in the notebook.
    ts = TSParams(
        threshold=0.01,
        stop_loss=0.10,
        take_profit=0.25,
        sizing_method="confidence",
        conf_scale=0.02,
        max_total_size=3.0,
        fee_bps=1.0
    )
    assets = {"gold": gold_series, "copper": copper_series}
    trade_results = run_trading_script_with_backtester(bt, assets, models, ts)

    # 7) Summary table (robust scalar extraction)
    START_CASH = 100_000.0
    rows = []
    for asset, per_model in trade_results.items():
        for model_name, res in per_model.items():
            df = res["df"]; m = res["metrics"]

            # --- robust scalar extraction ---
            eq_series = pd.to_numeric(df["equity"], errors="coerce").dropna()
            if not eq_series.empty:
                eq_last = eq_series.iloc[-1].item()
            else:
                eq_last = 1.0

            rows.append({
                "asset": asset,
                "model": model_name,
                "final_equity": eq_last,
                "final_portfolio_value": START_CASH * eq_last,
                "CAGR": m["CAGR"], "Sharpe": m["Sharpe"],
                "Sortino": m["Sortino"], "MaxDD": m["MaxDD"]
            })

    strategy_table = pd.DataFrame(rows).sort_values(["asset","model"])
    display(strategy_table)

if __name__ == "__main__":
    main()

# === Strategy helpers: params, sizing, trading loop ===
from dataclasses import dataclass
from typing import Optional, Dict, Any
import numpy as np
import pandas as pd

@dataclass
class TSParams:
    # Entry/exit
    threshold: float = 0.0           # enter long if forecast > price*(1+threshold)
    stop_loss: float = 0.05          # 5% SL
    take_profit: float = 0.10        # 10% TP
    max_holding_days: Optional[int] = None

    # Sizing
    sizing_method: str = "confidence"  # 'fixed'|'percentage'|'confidence'|'kelly'
    fixed_size: float = 1.0
    pct_of_notional: float = 0.25
    conf_scale: float = 0.05           # scale for 'confidence' sizing
    kelly_p: float = 0.55
    kelly_b: float = 1.0
    max_total_size: Optional[float] = 3.0

    # Costs
    fee_bps: float = 1.0               # 1bp per side

def _trade_cost(bps: float) -> float:
    return (bps or 0.0) / 10000.0

def _size_from_method(method: str, px: float, pred: float, p: TSParams) -> float:
    if method == "fixed":
        return float(p.fixed_size)
    if method == "percentage":
        return float(np.clip(p.pct_of_notional, 0.0, 1.0))
    if method == "confidence":
        rel = abs(pred - px) / max(px, 1e-12)
        return float(min(1.0, rel / max(p.conf_scale, 1e-6)))
    if method == "kelly":
        pr = np.clip(p.kelly_p, 1e-6, 1-1e-6); b = max(p.kelly_b, 1e-6)
        return float(np.clip(pr - (1-pr)/b, 0.0, 1.0))
    return 1.0

def apply_trading_script_rules(prices: pd.Series, forecast_prices: pd.Series, params: TSParams) -> pd.DataFrame:
    """
    Deterministic trading loop.
    Returns columns: price, ret, f_price, pos, unit, strategy_ret, equity.
    """
    prices = pd.to_numeric(prices, errors="coerce").dropna()
    forecast_prices = pd.to_numeric(forecast_prices, errors="coerce")
    idx = prices.index.intersection(forecast_prices.index)
    px = prices.reindex(idx)
    fp = forecast_prices.reindex(idx)

    df = pd.DataFrame({
        "price": px.astype(float),
        "ret": px.astype(float).pct_change().fillna(0.0),
        "f_price": fp
    })
    # guaranteed outputs
    df["pos"] = 0.0
    df["unit"] = 0.0
    df["strategy_ret"] = 0.0

    in_trade = False
    entry_px = None
    entry_side = 0.0    # +1 long
    size_mult = 0.0
    total_size = 0.0

    open_cost = _trade_cost(params.fee_bps)
    close_cost = _trade_cost(params.fee_bps)

    for i in range(1, len(df)):
        px_i = float(df.iat[i, df.columns.get_loc("price")])
        pred = df.iat[i, df.columns.get_loc("f_price")]

        if np.isnan(pred) or px_i <= 0.0:
            if in_trade:
                df.iat[i, df.columns.get_loc("pos")] = entry_side * size_mult
                df.iat[i, df.columns.get_loc("unit")] = total_size
                df.iat[i, df.columns.get_loc("strategy_ret")] = df.iat[i, df.columns.get_loc("pos")] * df.iat[i, df.columns.get_loc("ret")]
            continue

        want_long = (pred > px_i * (1.0 + params.threshold))

        if not in_trade:
            if want_long:
                entry_px = px_i; entry_side = 1.0
                size_mult = _size_from_method(params.sizing_method, px_i, pred, params)
                total_size = size_mult if params.max_total_size is None else min(size_mult, params.max_total_size)
                size_mult = total_size
                in_trade = True
                df.iat[i, df.columns.get_loc("pos")] = entry_side * size_mult
                df.iat[i, df.columns.get_loc("unit")] = total_size
                df.iat[i, df.columns.get_loc("strategy_ret")] = df.iat[i, df.columns.get_loc("pos")] * df.iat[i, df.columns.get_loc("ret")] - open_cost*abs(entry_side)
            continue

        # In-trade: risk controls + optional scale
        move = px_i / entry_px - 1.0
        exit_now = False
        if params.stop_loss is not None and move <= -params.stop_loss: exit_now = True
        if params.take_profit is not None and move >=  params.take_profit and not exit_now: exit_now = True

        if exit_now or (not want_long):
            df.iat[i, df.columns.get_loc("pos")] = 0.0
            df.iat[i, df.columns.get_loc("unit")] = 0.0
            df.iat[i, df.columns.get_loc("strategy_ret")] = size_mult * df.iat[i, df.columns.get_loc("ret")] - close_cost*abs(entry_side)
            in_trade = False; entry_px = None; entry_side = 0.0; size_mult = 0.0; total_size = 0.0
        else:
            if pred > px_i:
                add_mult = _size_from_method(params.sizing_method, px_i, pred, params)
                new_total = total_size + add_mult
                if params.max_total_size is not None:
                    new_total = float(min(new_total, params.max_total_size))
                total_size = new_total; size_mult = new_total
            df.iat[i, df.columns.get_loc("pos")] = entry_side * size_mult
            df.iat[i, df.columns.get_loc("unit")] = total_size
            df.iat[i, df.columns.get_loc("strategy_ret")] = df.iat[i, df.columns.get_loc("pos")] * df.iat[i, df.columns.get_loc("ret")]

    df["equity"] = (1.0 + df["strategy_ret"]).cumprod()
    return df

# === Runner: get forecasts via Backtester.walk_forward, then apply rules ===

def run_trading_script_with_backtester(bt_obj, assets: Dict[str, pd.Series], models: Dict[str, Any], ts_params: TSParams):
    """
    Your Backtester.walk_forward(series, model_instance) returns a DataFrame
    with ['y_pred','y_true'] on test dates.

    We align so the decision at t-1 uses the forecast for t (live trading causality).
    """
    def _metrics(equity: pd.Series, rets: pd.Series) -> Dict[str, float]:
        equity = pd.to_numeric(equity, errors="coerce").dropna()
        rets   = pd.to_numeric(rets,   errors="coerce").dropna()
        if equity.empty:
            return {"CAGR": 0.0, "Sharpe": 0.0, "MaxDD": 0.0, "Sortino": 0.0}
        T_days = (equity.index[-1] - equity.index[0]).days or max(len(equity), 1)
        years  = T_days / 365.25
        cagr   = equity.iloc[-1] ** (1/years) - 1 if years > 0 else 0.0
        mu     = rets.mean() * 252
        sig    = rets.std(ddof=0) * (252 ** 0.5)
        sharpe = mu / sig if sig > 1e-12 else 0.0
        maxdd  = (equity / equity.cummax() - 1.0).min()
        d_sig  = rets[rets < 0].std(ddof=0) * (252 ** 0.5)
        sortino = mu / d_sig if d_sig > 1e-12 else 0.0
        return {"CAGR": float(cagr), "Sharpe": float(sharpe), "MaxDD": float(maxdd), "Sortino": float(sortino)}

    out: Dict[str, Dict[str, Any]] = {}
    for asset_name, series in assets.items():
        out[asset_name] = {}
        for model_name, model_instance in models.items():  # <-- pass INSTANCES (RandomWalk(), AR1())
            fc_df = bt_obj.walk_forward(series, model_instance)   # -> DataFrame with ['y_pred','y_true']
            y_pred = pd.to_numeric(fc_df["y_pred"], errors="coerce") if "y_pred" in fc_df.columns else pd.to_numeric(fc_df.squeeze(), errors="coerce")

            # Align: forecast for t is used to decide at t-1
            f_for_signal  = y_pred.shift(-1)
            px_for_signal = series.reindex(f_for_signal.index).astype(float)
            mask = (~f_for_signal.isna()) & (~px_for_signal.isna())

            df = apply_trading_script_rules(px_for_signal[mask], f_for_signal[mask], ts_params)
            out[asset_name][model_name] = {
                "df": df,
                "metrics": _metrics(df["equity"], df["strategy_ret"]),
                "diag": {
                    "n_forecasts": int(y_pred.notna().sum()),
                    "n_signal_rows": int(mask.sum()),
                    "position_rate": float((df["pos"] != 0).mean()),
                },
            }
    return out

# === One function: evaluates errors and strategy; prints diagnostics ===

def run_all_with_strategy(gold_df: pd.DataFrame, copper_df: pd.DataFrame, ts: TSParams = TSParams()):
    # Build series (business days + fill)
    gold_series   = pd.to_numeric(gold_df["Close GC=F"], errors="coerce").dropna().asfreq("B").ffill()
    copper_series = pd.to_numeric(copper_df["Close HG=F"], errors="coerce").dropna().asfreq("B").ffill()

    # Backtester & model INSTANCES (your walk_forward expects instances)
    bt = Backtester(train_size=0.8, window=252)
    models = {"RW": RandomWalk(), "AR1": AR1()}

    # 1) ORIGINAL forecast errors (no trading)
    def _errors_for(series, model_instance):
        df = bt.walk_forward(series, model_instance)       # DataFrame ['y_pred','y_true']
        return float(((df["y_pred"] - df["y_true"])**2).mean()), float((df["y_pred"] - df["y_true"]).abs().mean())

    err_rows = []
    for asset_name, s in {"gold": gold_series, "copper": copper_series}.items():
        for mname, minst in models.items():
            mse, mae = _errors_for(s, minst)
            err_rows.append({"asset": asset_name, "model": mname, "MSE": mse, "MAE": mae})
    mse_mae_table = pd.DataFrame(err_rows).sort_values(["asset","model"])
    print("\n=== Original Forecast Errors (no trading) ===")
    display(mse_mae_table)

    # 2) Strategy on same forecasts
    assets = {"gold": gold_series, "copper": copper_series}
    trade_results = run_trading_script_with_backtester(bt, assets, models, ts)

    START_CASH = 100_000.0
    rows = []
    for asset, per_model in trade_results.items():
        for model_name, res in per_model.items():
            df = res["df"]; m = res["metrics"]
            eq_series = pd.to_numeric(df["equity"], errors="coerce").dropna()
            eq_last = eq_series.iloc[-1].item() if len(eq_series) else 1.0
            rows.append({
                "asset": asset, "model": model_name,
                "final_equity": eq_last,
                "final_portfolio_value": START_CASH * eq_last,
                "CAGR": m["CAGR"], "Sharpe": m["Sharpe"], "Sortino": m["Sortino"], "MaxDD": m["MaxDD"],
                "n_bars": len(df), "pos_bars": int((df["pos"] != 0).sum()),
                "signal_rate": float((df["pos"] != 0).mean()),
            })
    strategy_table = pd.DataFrame(rows).sort_values(["asset","model"])
    print("\n=== Trading Strategy Summary (threshold/SL/TP) ===")
    display(strategy_table)

    print("\nDiagnostics:")
    for a in trade_results:
        for m in trade_results[a]:
            print(a, m, trade_results[a][m]["diag"])

    return mse_mae_table, strategy_table, trade_results

# === Example usage ===
# Assumes you already have:
dh = DataHandler(start="2015-01-01", end="2024-01-01")
gold_df   = dh.get_df("gold",   "Close GC=F")
copper_df = dh.get_df("copper", "Close HG=F")

ts = TSParams(
    threshold=0.0,         # permissive so we actually take trades; tune up later (e.g., 0.0030.01)
    stop_loss=0.05,
    take_profit=0.10,
    sizing_method="confidence",
    conf_scale=0.05,
    fee_bps=1.0,
    max_total_size=3.0,
)

mse_mae_table, strategy_table, trade_results = run_all_with_strategy(gold_df, copper_df, ts)

# Quick proof that positions were used & equity moved:
for a, per_model in trade_results.items():
    for m, res in per_model.items():
        eq_last = float(pd.to_numeric(res["df"]["equity"], errors="coerce").iloc[-1])
        print(f"{a} {m} -> equity_last={eq_last:.4f}, diag={res['diag']}")

dh_2 =  DataHandler(start="2015-01-01", end="2024-01-01")
df = dh_2.merge_all_data()
df